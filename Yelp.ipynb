{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from yelp.client import Client\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "import heapq  \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_KEY = \"cv-xXEAMYyEV3UEF-AcDxBCH5TgNXveK9Gs_Sh9xITWYM6ob_6zKQYSCJKRMndCT6Flckrsj99lg_7GqSmoDDRYIr-3S4Dqe7CmfuwhSY_UAiYIQC_CP2QgpE4DTW3Yx\"\n",
    "\n",
    "# client = Client(API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract yelp reviews into reviews list\n",
    "\n",
    "reviews = []\n",
    "url = \"https://www.yelp.com/biz/barboncino-pizza-and-bar-brooklyn-2\"\n",
    "for i in range(1,10):\n",
    "    result = requests.get(url)\n",
    "    html = result.text\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    review_div = soup.find_all('div', {'class':'review-content'})\n",
    "    for element in review_div:\n",
    "        p = element.find('p')\n",
    "        if p:\n",
    "            reviews.append(p.text)\n",
    "    url = \"https://www.yelp.com/biz/barboncino-pizza-and-bar-brooklyn-2?start=\" + str(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment_words = ' '\n",
    "# stopwords = set(STOPWORDS) \n",
    "  \n",
    "# for val in reviews: \n",
    "\n",
    "#     val = str(val) \n",
    "\n",
    "#     tokens = val.split() \n",
    "      \n",
    "#     for i in range(len(tokens)): \n",
    "#         tokens[i] = tokens[i].lower() \n",
    "          \n",
    "#     for words in tokens: \n",
    "#         comment_words = comment_words + words + ' '\n",
    "  \n",
    "  \n",
    "# wordcloud = WordCloud(width = 800, height = 800, \n",
    "#                 background_color ='white', \n",
    "#                 stopwords = stopwords, \n",
    "#                 min_font_size = 10).generate(comment_words) \n",
    "  \n",
    "# plot                       \n",
    "# plt.figure(figsize = (6, 6), facecolor = None) \n",
    "# plt.imshow(wordcloud) \n",
    "# plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing (lowercase + remove punctuation)\n",
    "# reviews = [i.lower() for i in reviews]\n",
    "# reviews = [re.sub(\"[^\\w\\s]\", '', i) for i in reviews]\n",
    "# reviews = [i.replace(\"\\xa0\", '') for i in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize reviews\n",
    "# reviews_tk = [nltk.tokenize.SpaceTokenizer().tokenize(i) for i in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize with different n-grams\n",
    "# def ngrams(input, n):\n",
    "#     input = input.split(' ')\n",
    "#     output = []\n",
    "#     for i in range(len(input)-n+1):\n",
    "#         output.append(input[i:i+n])\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(s, n):\n",
    "    # Pre-process\n",
    "    s = [i.lower() for i in s]\n",
    "    s = [re.sub(\"[^\\w\\s]\", '', i) for i in s]\n",
    "    s = [i.replace(\"\\xa0\", '') for i in s]\n",
    "\n",
    "    # Break sentence in the token, remove empty tokens\n",
    "    tokens = [nltk.tokenize.SpaceTokenizer().tokenize(i) for i in s][0]\n",
    "    \n",
    "    # Use the zip function to help us generate n-grams\n",
    "    # Concatentate the tokens into ngrams and return\n",
    "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "    return [\" \".join(ngram) for ngram in ngrams]\n",
    "\n",
    "\n",
    "#[\" \".join(ngram) for ngram in ngrams]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yep 5',\n",
       " '5 stars',\n",
       " 'stars the',\n",
       " 'the pizza',\n",
       " 'pizza here',\n",
       " 'here is',\n",
       " 'is so',\n",
       " 'so damn',\n",
       " 'damn delicious',\n",
       " 'delicious split',\n",
       " 'split the',\n",
       " 'the soppressata',\n",
       " 'soppressata piccante',\n",
       " 'piccante pizza',\n",
       " 'pizza with',\n",
       " 'with hot',\n",
       " 'hot honey',\n",
       " 'honey and',\n",
       " 'and the',\n",
       " 'the speck',\n",
       " 'speck pizza',\n",
       " 'pizza with',\n",
       " 'with 2',\n",
       " '2 friends',\n",
       " 'friends if',\n",
       " 'if you',\n",
       " 'you like',\n",
       " 'like anything',\n",
       " 'anything remotely',\n",
       " 'remotely spicy',\n",
       " 'spicy not',\n",
       " 'not talking',\n",
       " 'talking really',\n",
       " 'really hot',\n",
       " 'hot get',\n",
       " 'get the',\n",
       " 'the soppressata',\n",
       " 'soppressata with',\n",
       " 'with the',\n",
       " 'the hot',\n",
       " 'hot honey',\n",
       " 'honey it',\n",
       " 'it is',\n",
       " 'is a',\n",
       " 'a game',\n",
       " 'game changer',\n",
       " 'changer i',\n",
       " 'i had',\n",
       " 'had a',\n",
       " 'a hard',\n",
       " 'hard time',\n",
       " 'time not',\n",
       " 'not woofing',\n",
       " 'woofing down',\n",
       " 'down the',\n",
       " 'the entire',\n",
       " 'entire pie',\n",
       " 'pie by',\n",
       " 'by myselfservice',\n",
       " 'myselfservice was',\n",
       " 'was fantastic',\n",
       " 'fantastic our',\n",
       " 'our server',\n",
       " 'server kept',\n",
       " 'kept up',\n",
       " 'up with',\n",
       " 'with our',\n",
       " 'our non',\n",
       " 'non stop',\n",
       " 'stop sarcasm',\n",
       " 'sarcasm and',\n",
       " 'and recommended',\n",
       " 'recommended a',\n",
       " 'a really',\n",
       " 'really lovely',\n",
       " 'lovely wine',\n",
       " 'wine for',\n",
       " 'for the',\n",
       " 'the tablevery',\n",
       " 'tablevery pleased',\n",
       " 'pleased that',\n",
       " 'that we',\n",
       " 'we ended',\n",
       " 'ended up',\n",
       " 'up here',\n",
       " 'here after',\n",
       " 'after the',\n",
       " 'the restaurant',\n",
       " 'restaurant we',\n",
       " 'we wanted',\n",
       " 'wanted to',\n",
       " 'to go',\n",
       " 'go to',\n",
       " 'to was',\n",
       " 'was closed',\n",
       " 'closed it',\n",
       " 'it was',\n",
       " 'was fate',\n",
       " 'fate will',\n",
       " 'will 100',\n",
       " '100 come',\n",
       " 'come back',\n",
       " 'back the',\n",
       " 'the next',\n",
       " 'next time',\n",
       " 'time i',\n",
       " 'i pay',\n",
       " 'pay a',\n",
       " 'a visit',\n",
       " 'visit to',\n",
       " 'to nyc']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_ngrams(reviews, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find word frequencies and store in dictionary\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "word_frequencies = {}\n",
    "\n",
    "for review in reviews_tk:  \n",
    "    for word in review:\n",
    "        if word not in stopwords:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide word frequencies by max frequency\n",
    "max_freq = max(word_frequencies.values())\n",
    "\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word] / max_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find review scores of reviews less than 50 words\n",
    "review_scores = {}  \n",
    "for review in reviews:  \n",
    "    for word in nltk.word_tokenize(review.lower()):\n",
    "        if word in word_frequencies.keys():\n",
    "            if len(review.split(' ')) < 60:\n",
    "                if review not in review_scores.keys():\n",
    "                    review_scores[review] = word_frequencies[word]\n",
    "                else:\n",
    "                    review_scores[review] += word_frequencies[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_reviews = heapq.nlargest(5, review_scores, key=review_scores.get)\n",
    "\n",
    "summary = ', '.join(summary_reviews)  \n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
